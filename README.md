# virtual-relaxation-hand-tracking

## Project Info
The nature and yoga scenes were created with Unity. Unity is a development platform that gives developers the ability to create games and experiences in 3D and 2D. It uses C# as the primary scripting language and comes with its own physics engine. The Meta Quest 2 was used as the VR headset for this project. To set up a Unity project and development environment for AR/VR, there are specific settings to be configured in Unity and on the headset itself. Meta Quest has documentation on their developer website for how to set up a development environment in Unity as well as how to enable the headset for development and testing. 
Unity is made up of a collection of Assets. Assets are essentially the files within a project. For example, Scenes are a special type of Asset in Unity where all or part of an application is created. Scenes are made up of GameObjects which act as physical objects or logical objects in the Unity Scene. These GameObjects can be formed into a hierarchical structure which determines how the GameObjects function and interact with each other. A single GameObject can be attached to many other objects, and this affects its behavior and functionality.
There are many VR frameworks and toolkits that can be used to create a VR application in Unity. The Oculus Integration toolkit was used in this project because it supports the use of hand tracking and Meta Avatars. Hand tracking is a feature for Meta Quest that allows a user to use their hands in place of the touch controllers. Meta Avatars are custom avatars that a user creates for their Meta account. The Avatars SDK can be used to import the user’s custom avatar into the scene so that its visible by the user and potentially other players. The OculusIntegrationSampleRig is used in a Unity scene to act as the player in VR. This sample rig is a hierarchical GameObject structure that contains the camera, hand anchors, and input interactors for hands and controllers. The AvatarSDKManagerHorizon is also used to import the user’s Meta Avatar.
Three scenes were created for the project: a starting scene, a nature scene, and a yoga scene. The starting scene contains two buttons to transition to either the nature scene or the yoga scene. The buttons can be pressed by moving your hand or controller downwards onto the button. The button was created by configuring a poke interactable, proximity surface, and a pointable plane which are a part of the Oculus Integration package.
When the nature scene button is pressed, the user is transported to an outdoor environment with grass, trees, and a waterfall. The user can hear birds chirping and leaves rustling in the wind. These sounds were implemented by using Unity’s AudioSource component which is used to play audio clips in an application. The grass was created with Unity’s terrain tools which can be used to transform a landscape and paint materials onto the land. The trees and waterfall were created with assets available in Unity’s Asset Store. 
When the yoga scene button is pressed, the player is met with a gym environment with exercise equipment placed around a room. The player is seated on a yoga mat and when they turn around, a mirrored version of themselves is sitting on the mat next to them. The mirrored version is the player’s custom avatar and mimics the player’s actions and movements. 

## Reference Links
[Link to Nature Assets used in nature scene and yoga scene](https://assetstore.unity.com/packages/3d/vegetation/trees/polygon-nature-low-poly-3d-art-by-synty-120152)

[Oculus Integration package](https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022)

[Meta Avatars SDK](https://developer.oculus.com/blog/meta-avatars-sdk-now-available/)